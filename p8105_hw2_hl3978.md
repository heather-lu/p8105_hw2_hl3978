p8105_hw2_hl3978
================
Heather Lu
2025-10-01

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# Problem 1

**1) load and clean pols-month dataset**

``` r
pols_month_df = 
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  #1) separate mon -> year, month, day
  separate(mon, into = c("year","month","day"), sep = "-", convert = TRUE) |>
  #2) month number-> month name
  mutate(month = factor(month.name[month], levels = month.name, ordered = TRUE)) |> 
  #3) create president 
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem")
    ) |> 
  select(-prez_gop, -prez_dem) |> 
  select(-day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**2) load and clean snp.csv**

``` r
snp_df = 
  read_csv("data/fivethirtyeight_datasets/snp.csv", show_col_types = FALSE) |>
  janitor::clean_names() |> 
  # 1) split date -> year, month, day)
  separate(date, 
           into = c("month","day","year"),
           sep = "/", fill = "right", convert = TRUE) |> 
  mutate(year = if_else(year <= 15, 2000L + year, 1900L + year)) |>
  # 2) month number -> month name (calendar order)
  mutate(month = factor(month.name[month], levels = month.name, ordered = TRUE)) |> 
  select(-day) |>
  # 4) arrange by year, month
  arrange(year, month) |>
  # 5) arrange year and month first
  select(year, month, everything())
```

**3) Load and clean unemployment data**

``` r
unemployment_df = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv", show_col_types = FALSE) |>
  janitor::clean_names() |> 
  # 1) pivot longer
  pivot_longer(cols = jan:dec,
               names_to = "month",
               values_to = "unemployment_rate") |> 
  # 2) make month values consistent
  mutate(
    month = case_match(month,
      "jan" ~ "January", "feb" ~ "February", "mar" ~ "March",
      "apr" ~ "April",   "may" ~ "May",      "jun" ~ "June",
      "jul" ~ "July",    "aug" ~ "August",   "sep" ~ "September",
      "oct" ~ "October", "nov" ~ "November", "dec" ~ "December"), 
    month = factor(month, levels = month.name, ordered = TRUE)
  ) |> 
  arrange(year, month) |> 
  select(year, month, unemployment_rate, everything())
```

**4) join datasets**

``` r
merged_df =
  pols_month_df |> 
  left_join(snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))
```

**5) Write a short paragraph about these datasets. Explain briefly what
each dataset contained, and describe the resulting dataset**

The pols-month dataset contains US political totals by party such as
numbers of Republican/Democratic governors, senators, and
representatives. It includes a date split into year and month, and
gop/dem under the president variable. It spans 1947–2015 with key
variables such as year, month, gov_gop, sen_gop, rep_gop, gov_dem,
sen_dem, rep_dem, president. The snp data contains monthly S&P 500
closing levels with corresponding year and month. It spans 1950–2015
with key variables such as year, month, close. The unemployment data
reports monthly unemployment rates originally in wide form (one column
per month); after pivoting to long/tidy form, it includes variables
year, month (full names), and unemployment_rate, covering 1948–2015 with
816. Merged df contains 822 and covers years 1947–2015.

# Problem 2

``` r
path <- "data/202509 Trash Wheel Collection Data.xlsx"

# Read and clean Mr. Trash wheel

mr_cleaned <- read_excel(
  path,
  sheet = "Mr. Trash Wheel",
  skip = 1,                   
  na = c("", "NA", "N/A")
)  |>
  janitor::clean_names() |>
  select(-x15, -x16) |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls)),
    wheel = "Mr. Trash Wheel"
  ) |>
  relocate(wheel)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
# Read and clean professor trash wheel

prof_cleaned <- read_excel(
  path,
  sheet = "Professor Trash Wheel",
  skip = 1,
  na = c("", "NA", "N/A")
) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(wheel = "Professor Trash Wheel"
  ) |> 
  relocate(wheel)

# Gwynnda

gwyn_cleaned <- read_excel(
  path,
  sheet = "Gwynns Falls Trash Wheel",
  skip = 1,
  na = c("", "NA", "N/A")
) |> 
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(wheel = "Gwynnda"
  ) |> 
  relocate(wheel)

# Combined trash wheel data

# fix year data type error
mr_cleaned <- mr_cleaned %>% mutate(year = suppressWarnings(as.integer(year)))

prof_cleaned <- prof_cleaned %>% mutate(year = suppressWarnings(as.integer(year)))

gwyn_cleaned <- gwyn_cleaned %>% mutate(year = suppressWarnings(as.integer(year)))


trashwheel_all <- bind_rows(mr_cleaned, prof_cleaned, gwyn_cleaned) |> 
  arrange(wheel, year, month, dumpster) |>    # consistent order
  select(any_of(c("wheel","year","month","date","dumpster")), everything())
```

**Write a paragraph about these data; you are encouraged to use inline
R. Be sure to note the number of observations in the resulting dataset,
and give examples of key variables.**

The final trashwheel_all dataset contains 1188 observations across 3
devices: Gwynnda, Mr. Trash Wheel, Professor Trash Wheel, spanning
2014–2025 and 707 distinct dumpsters. Key variables include wheel, year,
month, date, dumpster, weight_tons, volume_cubic_yards, plastic_bottles,
polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers,
sports_balls, homes_powered.

**For available data, what was the total weight of trash collected by
Professor Trash Wheel? What was the total number of cigarette butts
collected by Gwynnda in June of 2022?**

``` r
# total professor trash wheel

prof_total_weight =
  trashwheel_all |> 
  filter(wheel == "Professor Trash Wheel") |> 
  summarise(total_tons = sum(weight_tons, na.rm = TRUE)) |> 
  pull(total_tons)

prof_total_weight
```

    ## [1] 282.26

``` r
# total cigarette butts Gwynnda

gwyn_june2022_cigs =
  trashwheel_all |> 
  filter(wheel == "Gwynnda", year == 2022, month == "June") |> 
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE)) |> 
  pull(total_cigs)

gwyn_june2022_cigs
```

    ## [1] 18120

Professor Trash Wheel collected 282.26 tons total. Gwynnda collected
18120 cigarette butts in June of 2022.

# Problem \#3

**Load and clean Zip Codes.csv**

``` r
zip_df = read_csv("data/zillow_data/Zip Codes.csv", show_col_types = FALSE) |> 
  janitor::clean_names() |> 
  distinct(zip_code, .keep_all = TRUE) #remove duplicates for merging
```

**Load and clean Zip NYC**

``` r
zori_df = read_csv("data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  janitor::clean_names() |> 
  rename(zip_code = region_name) |>
  pivot_longer(cols = -c(region_id, size_rank, zip_code, region_type, state_name, state, city, metro, county_name),
    names_to  = "date_str",
    values_to = "zori"
  ) |> 
  mutate(
    date_str = sub("^x", "", date_str),         # drop "x"
    date_str = gsub("_", "-", date_str),        # _ -> -
    date     = as.Date(date_str, format = "%Y-%m-%d"),
    year     = as.integer(format(date, "%Y")),
    month    = factor(format(date, "%B"), levels = month.name, ordered = TRUE),
    zori     = as.numeric(zori)
  ) |> 
  select(
    zip_code, year, month, date, zori,
    region_id, size_rank, region_type, state_name, state, city, metro, county_name
  ) |>
  arrange(zip_code, year, month)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**Merge zip_df and zori_df**

``` r
merged_df = zori_df |> 
  left_join(zip_df, by = "zip_code") |> 
  relocate(zip_code, year, month, date, zori, .before = 1) |> 
  arrange(year, month, zip_code)
```

# Merged data set description

**Briefly describe the resulting tidy dataset. How many total
observations exist? How many unique ZIP codes are included, and how many
unique neighborhoods?**

The merged_df spans 2015–2024 with key variables such as zip_code, year,
month, date, zori, region_id, size_rank, region_type, state_name, state,
city, metro, county_name, county, state_fips, county_code, county_fips,
file_date, neighborhood. The merged_df contains 17284 observations. The
merged_df contains 149 unique zip codes and 43 unique neighborhoods.

**Which ZIP codes appear in the ZIP code dataset but not in the Zillow
Rental Price dataset? Using a few illustrative examples discuss why
these ZIP codes might be excluded from the Zillow dataset.**

``` r
zip_lu <- zip_df |> distinct(zip_code, .keep_all = TRUE)
zip_missing <- zip_lu |>
  anti_join(zori_df |> distinct(zip_code), by = "zip_code")

n_missing <- nrow(zip_missing)
n_missing
```

    ## [1] 171

From the result above, we see that there are 171 missing zip codes that
are in the ZIP code data set but are not in the Zillow Rental Price data
set. This could be because these areas are non-residential, PO boxes,
and lack of coverage.

**For all available ZIP codes, compare rental prices in January 2021 to
prices in January 2020. Make a table that shows the 10 ZIP codes with
largest drop in price from January 2020 to 2021.**

``` r
jan20 <- merged_df |>
  filter(year == 2020, month == "January") |>
  select(zip_code, zori_2020 = zori)

jan21 <- merged_df |>
  filter(year == 2021, month == "January") |>
  select(zip_code, zori_2021 = zori)

covid_change <- inner_join(jan20, jan21, by = "zip_code")

covid_change <- covid_change |>
  mutate(
    change = zori_2021 - zori_2020,
  )

zip_info <- merged_df |>
  distinct(zip_code, county_name, neighborhood) |>
  mutate(
    borough = recode(
      county_name,
      "New York" = "Manhattan",
      "Kings"    = "Brooklyn",
      "Bronx"    = "Bronx",
      "Queens"   = "Queens",
      "Richmond" = "Staten Island",
      .default   = county_name
    )
  )

covid_change <- left_join(covid_change, zip_info, by = "zip_code")

top10_table <- covid_change |> 
  transmute(
    ZIP = zip_code,
    Borough = borough,
    Neighborhood = neighborhood,
    `ZORI Jan 2020` = round(zori_2020),
    `ZORI Jan 2021` = round(zori_2021),
    `Change` = round(change)
  )

top10_table
```

    ## # A tibble: 149 × 6
    ##      ZIP Borough         Neighborhood     `ZORI Jan 2020` `ZORI Jan 2021` Change
    ##    <dbl> <chr>           <chr>                      <dbl>           <dbl>  <dbl>
    ##  1 10001 New York County Chelsea and Cli…            4108            3398   -710
    ##  2 10002 New York County Lower East Side             3645            2935   -710
    ##  3 10003 New York County Lower East Side             3570            2897   -673
    ##  4 10004 New York County Lower Manhattan             3150            2444   -706
    ##  5 10005 New York County Lower Manhattan             3408            2918   -490
    ##  6 10006 New York County Lower Manhattan               NA            2956     NA
    ##  7 10007 New York County Lower Manhattan             6334            5422   -913
    ##  8 10009 New York County Lower East Side             3406            2692   -714
    ##  9 10010 New York County Gramercy Park a…            3697            3012   -685
    ## 10 10011 New York County Chelsea and Cli…            4104            3442   -662
    ## # ℹ 139 more rows

The top 10 largest price drops between 2020-2021 are in New York County
(Manhattan), in neighborhoods such as lower Manhattan, lower east side,
Chelsea/Clinton, and Greenwhich village/Soho. The largest observed drop
was in lower Manhattan, by -912 ZORI.
