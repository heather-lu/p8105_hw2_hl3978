---
title: "p8105_hw2_hl3978"
author: "Heather Lu"
date: "2025-10-01"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```


# Problem 1

**1) load and clean pols-month dataset**
```{r setup}

pols_month_df = 
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  #1) separate mon -> year, month, day
  separate(mon, into = c("year","month","day"), sep = "-", convert = TRUE) |>
  #2) month number-> month name
  mutate(month = factor(month.name[month], levels = month.name, ordered = TRUE)) |> 
  #3) create president 
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem")
    ) |> 
  select(-prez_gop, -prez_dem) |> 
  select(-day)
```


**2) load and clean snp.csv**

```{r}

snp_df = 
  read_csv("data/fivethirtyeight_datasets/snp.csv", show_col_types = FALSE) |>
  janitor::clean_names() |> 
  # 1) split date -> year, month, day)
  separate(date, 
           into = c("month","day","year"),
           sep = "/", fill = "right", convert = TRUE) |> 
  mutate(year = if_else(year <= 15, 2000L + year, 1900L + year)) |>
  # 2) month number -> month name (calendar order)
  mutate(month = factor(month.name[month], levels = month.name, ordered = TRUE)) |> 
  select(-day) |>
  # 4) arrange by year, month
  arrange(year, month) |>
  # 5) arrange year and month first
  select(year, month, everything())

```

**3) Load and clean unemployment data**

```{r}
unemployment_df = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv", show_col_types = FALSE) |>
  janitor::clean_names() |> 
  # 1) pivot longer
  pivot_longer(cols = jan:dec,
               names_to = "month",
               values_to = "unemployment_rate") |> 
  # 2) make month values consistent
  mutate(
    month = case_match(month,
      "jan" ~ "January", "feb" ~ "February", "mar" ~ "March",
      "apr" ~ "April",   "may" ~ "May",      "jun" ~ "June",
      "jul" ~ "July",    "aug" ~ "August",   "sep" ~ "September",
      "oct" ~ "October", "nov" ~ "November", "dec" ~ "December"), 
    month = factor(month, levels = month.name, ordered = TRUE)
  ) |> 
  arrange(year, month) |> 
  select(year, month, unemployment_rate, everything())
```

**4) join datasets**

```{r}
merged_df =
  pols_month_df |> 
  left_join(snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))
```

**5) Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset**

The pols-month dataset contains US political totals by party such as numbers of Republican/Democratic governors, senators, and representatives. It includes a date split into year and month, and gop/dem under the president variable. It spans `r min(pols_month_df$year)`–`r max(pols_month_df$year)` with key variables such as `r toString(names(pols_month_df))`. The snp data contains monthly S&P 500 closing levels with corresponding year and month. It spans `r min(snp_df$year)`–`r max(snp_df$year)` with key variables such as `r toString(names(snp_df))`. The unemployment data reports monthly unemployment rates originally in wide form (one column per month); after pivoting to long/tidy form, it includes variables year, month (full names), and unemployment_rate, covering `r min(unemployment_df$year)`–`r max(unemployment_df$year)` with `r nrow(unemployment_df)`. Merged df contains `r nrow(merged_df)` and covers years `r min(merged_df$year)`–`r max(merged_df$year)`.

# Problem 2

```{r}
path <- "data/202509 Trash Wheel Collection Data.xlsx"

# Read and clean Mr. Trash wheel

mr_cleaned <- read_excel(
  path,
  sheet = "Mr. Trash Wheel",
  skip = 1,                   
  na = c("", "NA", "N/A")
)  |>
  janitor::clean_names() |>
  select(-x15, -x16) |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls)),
    wheel = "Mr. Trash Wheel"
  ) |>
  relocate(wheel)

# Read and clean professor trash wheel

prof_cleaned <- read_excel(
  path,
  sheet = "Professor Trash Wheel",
  skip = 1,
  na = c("", "NA", "N/A")
) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(wheel = "Professor Trash Wheel"
  ) |> 
  relocate(wheel)

# Gwynnda

gwyn_cleaned <- read_excel(
  path,
  sheet = "Gwynns Falls Trash Wheel",
  skip = 1,
  na = c("", "NA", "N/A")
) |> 
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(wheel = "Gwynnda"
  ) |> 
  relocate(wheel)

# Combined trash wheel data

# fix year data type error
mr_cleaned <- mr_cleaned %>% mutate(year = suppressWarnings(as.integer(year)))

prof_cleaned <- prof_cleaned %>% mutate(year = suppressWarnings(as.integer(year)))

gwyn_cleaned <- gwyn_cleaned %>% mutate(year = suppressWarnings(as.integer(year)))


trashwheel_all <- bind_rows(mr_cleaned, prof_cleaned, gwyn_cleaned) |> 
  arrange(wheel, year, month, dumpster) |>    # consistent order
  select(any_of(c("wheel","year","month","date","dumpster")), everything())
```

**Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables.**

The final trashwheel_all dataset contains `r nrow(trashwheel_all)` observations across `r n_distinct(trashwheel_all$wheel)` devices: `r toString(sort(unique(trashwheel_all$wheel)))`, spanning `r min(trashwheel_all$year, na.rm=TRUE)`–`r max(trashwheel_all$year, na.rm=TRUE)` and `r n_distinct(trashwheel_all$dumpster)` distinct dumpsters. Key variables include `r toString(names(trashwheel_all))`.

**For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?**

```{r}
# total professor trash wheel

prof_total_weight =
  trashwheel_all |> 
  filter(wheel == "Professor Trash Wheel") |> 
  summarise(total_tons = sum(weight_tons, na.rm = TRUE)) |> 
  pull(total_tons)

prof_total_weight

# total cigarette butts Gwynnda

gwyn_june2022_cigs =
  trashwheel_all |> 
  filter(wheel == "Gwynnda", year == 2022, month == "June") |> 
  summarise(total_cigs = sum(cigarette_butts, na.rm = TRUE)) |> 
  pull(total_cigs)

gwyn_june2022_cigs

```

Professor Trash Wheel collected 282.26 tons total. Gwynnda collected 18120 cigarette butts in June of 2022.

# Problem #3 

**Load and clean Zip Codes.csv**

```{r}
zip_df = read_csv("data/zillow_data/Zip Codes.csv", show_col_types = FALSE) |> 
  janitor::clean_names() |> 
  distinct(zip_code, .keep_all = TRUE) #remove duplicates for merging
```

**Load and clean Zip NYC**

```{r}
zori_df = read_csv("data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  janitor::clean_names() |> 
  rename(zip_code = region_name) |>
  pivot_longer(cols = -c(region_id, size_rank, zip_code, region_type, state_name, state, city, metro, county_name),
    names_to  = "date_str",
    values_to = "zori"
  ) |> 
  mutate(
    date_str = sub("^x", "", date_str),         # drop "x"
    date_str = gsub("_", "-", date_str),        # _ -> -
    date     = as.Date(date_str, format = "%Y-%m-%d"),
    year     = as.integer(format(date, "%Y")),
    month    = factor(format(date, "%B"), levels = month.name, ordered = TRUE),
    zori     = as.numeric(zori)
  ) |> 
  select(
    zip_code, year, month, date, zori,
    region_id, size_rank, region_type, state_name, state, city, metro, county_name
  ) |>
  arrange(zip_code, year, month)
```
**Merge zip_df and zori_df**

```{r}
merged_df = zori_df |> 
  left_join(zip_df, by = "zip_code") |> 
  relocate(zip_code, year, month, date, zori, .before = 1) |> 
  arrange(year, month, zip_code)
```

# Merged data set description

**Briefly describe the resulting tidy dataset. How many total observations exist? How many unique ZIP codes are included, and how many unique neighborhoods?**

The merged_df spans `r min(merged_df$year)`–`r max(merged_df$year)` with key variables such as `r paste(names(merged_df), collapse = ", ")`. The merged_df contains `r nrow(merged_df)` observations. The merged_df contains `r length(unique(zori_df$zip_code))` unique zip codes and `r length(unique(zip_df$neighborhood))` unique neighborhoods.

**Which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset? Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.**

```{r}
zip_lu <- zip_df |> distinct(zip_code, .keep_all = TRUE)
zip_missing <- zip_lu |>
  anti_join(zori_df |> distinct(zip_code), by = "zip_code")

n_missing <- nrow(zip_missing)
n_missing
```

From the result above, we see that there are 171 missing zip codes that are in the ZIP code data set but are not in the Zillow Rental Price data set. This could be because these areas are non-residential, PO boxes, and lack of coverage.

**For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. Make a table that shows the 10 ZIP codes with largest drop in price from January 2020 to 2021.**

```{r}

jan20 <- merged_df |>
  filter(year == 2020, month == "January") |>
  select(zip_code, zori_2020 = zori)

jan21 <- merged_df |>
  filter(year == 2021, month == "January") |>
  select(zip_code, zori_2021 = zori)

covid_change <- inner_join(jan20, jan21, by = "zip_code")

covid_change <- covid_change |>
  mutate(
    change = zori_2021 - zori_2020,
  )

zip_info <- merged_df |>
  distinct(zip_code, county_name, neighborhood) |>
  mutate(
    borough = recode(
      county_name,
      "New York" = "Manhattan",
      "Kings"    = "Brooklyn",
      "Bronx"    = "Bronx",
      "Queens"   = "Queens",
      "Richmond" = "Staten Island",
      .default   = county_name
    )
  )

covid_change <- left_join(covid_change, zip_info, by = "zip_code")

top10_table <- covid_change |> 
  transmute(
    ZIP = zip_code,
    Borough = borough,
    Neighborhood = neighborhood,
    `ZORI Jan 2020` = round(zori_2020),
    `ZORI Jan 2021` = round(zori_2021),
    `Change` = round(change)
  )

top10_table

```

The top 10 largest price drops between 2020-2021 are in New York County (Manhattan), in neighborhoods such as lower Manhattan, lower east side, Chelsea/Clinton, and Greenwhich village/Soho. The largest observed drop was in lower Manhattan, by -912 ZORI. 



